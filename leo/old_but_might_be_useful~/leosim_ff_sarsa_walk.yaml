experiment: 
  type: experiment/online_learning
  runs: 1
  trials: 0
  steps: 1000000
  rate: 0
  test_interval: 10
  output: leosim_ff_sarsa_walk
  environment: 
    type: environment/leo_walk
    xml: ../../leo/cfg/leo_walk.xml
    target_env: 
      type: environment/ode
      xml: experiment/environment/xml
      randomize: 0
      visualize: 1
    observe: torso_boom, hipright, hipleft, kneeright, kneeleft
    actuate: hipright, hipleft, kneeleft
    observation_dims: experiment/environment/target_env/observation_dims
    action_dims: experiment/environment/target_env/action_dims
  agent: 
    type: agent/master/sequential
    agent1: 
      type: agent/fixed
      policy: 
        type: policy/feed_forward
        input: /home/ivan/work/Project/Software/grl/src/grl/addons/leo/csv/walking.csv
    agent2: 
      type: agent/td
      policy: 
        type: mapping/policy/value/q
        discretizer: 
          type: discretizer/uniform
          min: experiment/environment/action_min
          max: experiment/environment/action_max
          steps: [7, 7, 7]
        projector: 
          type: projector/tile_coding
          tilings: 16
          memory: 25165824
          resolution: [0.14, 0.28, 0.28, 0.28, 0.28, 5, 10, 10, 10, 10, 6.67, 6.67, 6.67]
          wrapping: []
        representation: 
          type: representation/parameterized/linear
          init_min: [0]
          init_max: [0.01]
          memory: experiment/agent/agent2/policy/projector/memory
          outputs: 1
          output_min: []
          output_max: []
        sampler: 
          type: sampler/epsilon_greedy
          epsilon: 0.05
      predictor: 
        type: predictor/sarsa
        alpha: 0.2
        gamma: 0.9962
        lambda: 0.8582
        projector: experiment/agent/agent2/policy/projector
        representation: experiment/agent/agent2/policy/representation
        trace: 
          type: trace/enumerated/accumulating
  test_agent: experiment/agent
  save_every: never
