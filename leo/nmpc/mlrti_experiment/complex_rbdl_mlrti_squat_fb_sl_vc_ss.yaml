experiment: 
  type: experiment/online_learning
  runs: 1
  trials: 1
  steps: 0
  rate: 30
  test_interval: 0
  output: complex_rbdl_mlrti_squat_fb_sl_vc_ss
  environment: 
    type: environment/sandbox
    model: 
      type: sandbox_model/leo_squatting
      control_step: 0.03
      integration_steps: 25
      target_dof: 4
      dynamics: 
        type: dynamics/rbdl
        file: leo_vc/leo_fb_sl.lua
        points: tip_left, heel_left, root
        auxiliary: mm, com, comv, am
      animation: immediate
      lower_height: 0.28
      upper_height: 0.35
      precision: [0.01, 0.04]
      mode: vc
      sim_filtered: 0
      sub_sma_state: 
        type: signal/vector
      timer_switch: 0
    task: 
      type: task/leo_squatting
      target_env: experiment/environment/model/target_env
      timeout: 5000
      randomize: 0
      weight_nmpc: 0.0001
      weight_nmpc_aux: 1
      weight_nmpc_qd: 1
      weight_shaping: 0
      power: 2
      use_mef: 0
      setpoint_reward: 0
      continue_after_fall: 1
      gamma: 0
      fixed_arm: 0
    exporter: 
      type: exporter/csv
      file: complex_rbdl_mlrti_squat_fb_sl_vc_ss
      fields: time, state, observation, action, reward, terminal
      style: meshup
      variant: test
      precision: 6
      enabled: 1
  agent: 
    type: agent/leo/sma
    action_min: experiment/environment/task/action_min
    action_max: experiment/environment/task/action_max
    agent_prepare: 
      type: agent/leo/fixed
      policy: 
        type: mapping/policy/parameterized/pid
        setpoint: [1.06, -2.13, 1.27, -0.26, 0, 0, 0, 0, 0]
        outputs: 4
        p: [40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 0, 0, 0, 0, 0]
        i: []
        d: []
        il: []
        action_min: experiment/environment/task/action_min
        action_max: experiment/environment/task/action_max
    agent_standup: 
      type: agent/leo/fixed
      policy: 
        type: mapping/policy/parameterized/pid
        setpoint: [1.06, -2.13, 1.27, -0.26, 0, 0, 0, 0, 0]
        outputs: 4
        p: [40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 0, 0, 0, 0, 0]
        i: []
        d: []
        il: []
        action_min: experiment/environment/task/action_min
        action_max: experiment/environment/task/action_max
    agent_main: 
      type: agent/fixed
      policy: 
        type: mapping/policy/nmpc_mlrti
        verbose: 0
        initFeedback: 1
        action_min: experiment/environment/task/action_min
        action_max: experiment/environment/task/action_max
        lua_model: leo_fb_sl.lua
        model_name: nmpc_leo_squat_fb_sl_vc
        nmpc_model_name: nmpc_leo_squat_fb_sl_vc
    main_timeout: 30.0
    upright_trigger: 
      type: trigger
      min: []
      max: []
      delay: 5000
    feet_on_trigger: 
      type: trigger
      min: [1]
      max: [1]
      delay: 5
    pub_sma_state: experiment/environment/model/sub_sma_state
  test_agent: experiment/agent
  save_every: never
