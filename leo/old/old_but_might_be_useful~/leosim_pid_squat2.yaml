experiment: 
  type: experiment/online_learning
  runs: 1
  trials: 0
  steps: 0
  rate: 30
  test_interval: 0
  output: leosim_pid_squat
  environment: 
    type: environment/leo_squat
    xml: ../../leo/cfg/leo_learn_squatting.xml
    target_env: 
      type: environment/ode
      xml: experiment/environment/xml
      randomize: 0
      visualize: 1
    observe: hipright, kneeright, ankleright, direction
    actuate: hip, knee, ankle
    observation_dims: experiment/environment/target_env/observation_dims
    action_dims: experiment/environment/target_env/action_dims
  agent: 
    type: agent/master/exclusive
    gamma: 0.97
    agent1: 
      type: agent/sub/compartmentalized
      min: [-3.1415, -3.1415, -3.1415, -31.4159, -31.4159, -31.4159, 0]
      max: [3.1415, 3.1415, 3.1415, 31.4159, 31.4159, 31.4159, 1]
      agent: 
        type: agent/fixed
        policy: 
          type: policy/parameterized/pid
          setpoint: [0.2, -0.2, 0.1, 0, 0, 0]
          outputs: 3
          p: [5.7, 0, 0, 0, 5.75, 0, 0, 0, 8.0, 0.6, 0, 0, 0, 0.8, 0, 0, 0, 0.65]
          i: []
          d: []
          il: []
    agent2: 
      type: agent/sub/compartmentalized
      min: [-3.1415, -3.1415, -3.1415, -31.4159, -31.4159, -31.4159, -1]
      max: [3.1415, 3.1415, 3.1415, 31.4159, 31.4159, 31.4159, 0]
      agent: 
        type: agent/fixed
        policy: 
          type: policy/parameterized/pid
          setpoint: [1.6, -1.9, 0.85, 0, 0, 0]
          outputs: 3
          p: [5.5, 0, 0, 0, 6.1, 0, 0, 0, 7.35, 1, 0, 0, 0, 2.1, 0, 0, 0, 2.06]
          i: []
          d: []
          il: []
  test_agent: experiment/agent
  save_every: never
