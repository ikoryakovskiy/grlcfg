experiment: 
  type: experiment/online_learning
  runs: 1
  trials: 0
  steps: 0
  rate: 10
  test_interval: 0
  output: complex_leosim_sarsa_walk_egreedy_play
  environment: 
    type: environment/leo_walk
    behavior: 
      type: behavior/leo_walk
    xml: ../../leo/cfg/xm430_210_vc_leo_walk_real.xml
    target_env: 
      type: environment/ode
      xml: experiment/environment/xml
      randomize: 0
      visualize: 1
    observe: hipleft, hipright, kneeleft, kneeright, ankleleft, ankleright, shoulder, torso_boom
    actuate: hipleft, hipright, kneeleft, kneeright, ankleleft, ankleright, shoulder
    exporter: 
      type: exporter/csv
      file: complex_leosim_sarsa_walk_egreedy_play
      style: meshup
      variant: all
      enabled: 1
    sub_transition_type: 
      type: signal/vector
    pub_ic_signal: 
      type: signal/vector
    measurement_noise: 0
  agent: 
    type: agent/leo/sma
    sub_ic_signal: experiment/environment/pub_ic_signal
    action_min: experiment/environment/action_min
    action_max: experiment/environment/action_max
    agent_prepare: 
      type: agent/leo/fixed
      policy: 
        type: mapping/policy/parameterized/pid
        setpoint: [0.100951, 0.819996, 0.001465, -1.269998, 0.0, 0.0, -0.261799, -0.101485, 0, 0, 0, 0, 0, 0, 0, 0]
        outputs: 7
        p: [20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 60, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0]
        i: []
        d: []
        il: []
        action_min: experiment/environment/action_min
        action_max: experiment/environment/action_max
      pub_transition_type: experiment/environment/sub_transition_type
    agent_standup: 
      type: agent/leo/fixed
      policy: 
        type: mapping/policy/parameterized/pid
        setpoint: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
        outputs: 7
        p: []
        i: []
        d: []
        il: []
        action_min: experiment/environment/action_min
        action_max: experiment/environment/action_max
      pub_transition_type: experiment/environment/sub_transition_type
    agent_starter: 
      type: agent/leo/fixed
      policy: 
        type: mapping/policy/parameterized/pidt
        trajectory: 
          type: mapping/timeline
          importer: 
            type: importer/csv
            file: ../src/grl/addons/leo/csv/complex_leosim_walkdynamic-test-0-converted
            fields: time, state0
        inputs: 16
        outputs: 7
        p: [20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0]
        i: []
        d: []
        il: []
        action_min: experiment/environment/action_min
        action_max: experiment/environment/action_max
      pub_transition_type: experiment/environment/sub_transition_type
    agent_main: 
      type: agent/leo/sym_wrapper
      sub_ic_signal: experiment/environment/pub_ic_signal
      action_min: experiment/environment/action_min
      action_max: experiment/environment/action_max
      agent: 
        type: agent/leo/td
        policy: 
          type: mapping/policy/value/q
          discretizer: 
            type: discretizer/uniform
            min: [-8.56, -8.56, -8.56]
            max: [8.56, 8.56, 8.56]
            steps: [7, 7, 7]
          projector: 
            type: projector/tile_coding
            tilings: 16
            memory: 33554432
            safe: 1
            resolution: [0.28, 0.28, 0.28, 0.28, 0.14, 10, 10, 10, 10, 5, 5.33, 5.33, 5.33]
            wrapping: []
          representation: 
            type: representation/parameterized/linear
            init_min: [0]
            init_max: [0.01]
            memory: experiment/agent/agent_main/agent/policy/projector/memory
            outputs: 1
            output_min: []
            output_max: []
          sampler: 
            type: sampler/epsilon_greedy
            rand_max: 0
            epsilon: [0.05]
            decay: []
        predictor: 
          type: predictor/sarsa
          alpha: 0.2
          gamma: 0.9962
          lambda: 0.8582
          projector: experiment/agent/agent_main/agent/policy/projector
          representation: experiment/agent/agent_main/agent/policy/representation
          trace: 
            type: trace/enumerated/accumulating
        pub_transition_type: experiment/environment/sub_transition_type
    upright_trigger: 
      type: trigger
      min: [-0.3, -0.3, -0.6, -0.6, -3.14, -3.14, -100000, -0.2, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]
      max: [0.3, 0.3, 0.1, 0.1, 3.14, 3.14, 100000, 0.2, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
      delay: 0.5
    feet_on_trigger: 
      type: trigger
      min: [0.9]
      max: [1.1]
      delay: 0.5
    feet_off_trigger: 
      type: trigger
      min: [ -0.1 ]
      max: [ 0.1 ]
      delay: 0.5
    starter_trigger: 
      type: trigger
      min: []
      max: []
      delay: 0.0
  test_agent: 
    type: agent/leo/sma
    sub_ic_signal: experiment/environment/pub_ic_signal
    action_min: experiment/agent/action_min
    action_max: experiment/agent/action_max
    agent_prepare: experiment/agent/agent_prepare
    agent_standup: experiment/agent/agent_standup
    agent_starter: experiment/agent/agent_starter
    agent_main: 
      type: agent/leo/sym_wrapper
      sub_ic_signal: experiment/environment/pub_ic_signal
      action_min: experiment/agent/action_min
      action_max: experiment/agent/action_max
      agent: 
        type: agent/leo/fixed
        policy: 
          type: mapping/policy/value/q
          discretizer: experiment/agent/agent_main/agent/policy/discretizer
          projector: experiment/agent/agent_main/agent/policy/projector
          representation: experiment/agent/agent_main/agent/policy/representation
          sampler: 
            type: sampler/greedy
            rand_max: 0
        pub_transition_type: experiment/environment/sub_transition_type
    upright_trigger: experiment/agent/upright_trigger
    feet_on_trigger: experiment/agent/feet_on_trigger
    feet_off_trigger: experiment/agent/feet_off_trigger
    starter_trigger: experiment/agent/starter_trigger
  load_file: leo_walk/leo_leosim_dsarsa_walk_egreedy-cf002-mp3-run0
  save_every: never
