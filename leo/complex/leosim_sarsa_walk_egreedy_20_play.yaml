experiment: 
  type: experiment/online_learning
  runs: 1
  trials: 0
  steps: 0
  rate: 30
  test_interval: 0
  output: complex_leosim_sarsa_walk_egreedy_play
  environment: 
    type: environment/leo_walk
    behavior: 
      type: behavior/leo_walk
    xml: ../../leo/cfg/xm430_210_vc_leo_walk_real.xml
    target_env: 
      type: environment/ode
      xml: experiment/environment/xml
      randomize: 0
      visualize: 1
    observe: torso_boom, shoulder, hipright, hipleft, kneeright, kneeleft, ankleright, ankleleft
    actuate: shoulder, hipright, hipleft, kneeright, kneeleft, ankleright, ankleleft
    exporter: 
      type: exporter/csv
      file: complex_leosim_sarsa_walk_egreedy_play
      style: meshup
      variant: all
      enabled: 1
    sub_transition_type: 
      type: signal/vector
    pub_ic_signal: 
      type: signal/vector
  agent: 
    type: agent/leo/sma
    agent_prepare: 
      type: agent/fixed
      policy: 
        type: mapping/policy/parameterized/pid
        setpoint: [-0.101485, -0.261799, 0.819996, 0.100951, -1.269998, 0.001465, 0.0, '4e-06', 0, 0, 0, 0, 0, 0, 0, 0]
        outputs: 7
        p: [0, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 60, 0, 0, 0, 0, 0, 0, 0, 0]
        i: []
        d: []
        il: []
        action_min: experiment/environment/action_min
        action_max: experiment/environment/action_max
    agent_standup: 
      type: agent/fixed
      policy: 
        type: mapping/policy/parameterized/pid
        setpoint: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
        outputs: 7
        p: []
        i: []
        d: []
        il: []
        action_min: experiment/environment/action_min
        action_max: experiment/environment/action_max
    agent_main: 
      type: agent/leo/sym_wrapper
      agent: 
        type: agent/leo/td
        policy: 
          type: mapping/policy/value/q
          discretizer: 
            type: discretizer/uniform
            min: [-10.7, -10.7, -10.7]
            max: [10.7, 10.7, 10.7]
            steps: [7, 7, 7]
          projector: 
            type: projector/tile_coding
            tilings: 16
            memory: 33554432
            safe: 1
            resolution: [0.14, 0.28, 0.28, 0.28, 0.28, 5, 10, 10, 10, 10, 6.67, 6.67, 6.67]
            wrapping: []
          representation: 
            type: representation/parameterized/linear
            init_min: [0]
            init_max: [0.01]
            memory: experiment/agent/agent_main/agent/policy/projector/memory
            outputs: 1
            output_min: []
            output_max: []
          sampler: 
            type: sampler/epsilon_greedy
            rand_max: 0
            epsilon: [ 0.05 ]
        predictor: 
          type: predictor/sarsa
          alpha: 0.2
          gamma: 0.9962
          lambda: 0.8582
          projector: experiment/agent/agent_main/agent/policy/projector
          representation: experiment/agent/agent_main/agent/policy/representation
          trace: 
            type: trace/enumerated/accumulating
        pub_transition_type: experiment/environment/sub_transition_type
      sub_ic_signal: experiment/environment/pub_ic_signal
    trigger: 
      type: trigger
      min: [-0.2, -100000, -0.3, -0.3, -0.6, -0.6, -3.14, -3.14, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]
      max: [0.2, 100000, 0.3, 0.3, 0.1, 0.1, 3.14, 3.14, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
      delay: 0
    pub_ic_signal: experiment/environment/pub_ic_signal
  test_agent: 
    type: agent/leo/sma
    agent_prepare: experiment/agent/agent_prepare
    agent_standup: experiment/agent/agent_standup
    agent_main: 
      type: agent/leo/sym_wrapper
      agent: 
        type: agent/leo/fixed
        policy: 
          type: mapping/policy/value/q
          discretizer: experiment/agent/agent_main/agent/policy/discretizer
          projector: experiment/agent/agent_main/agent/policy/projector
          representation: experiment/agent/agent_main/agent/policy/representation
          sampler: 
            type: sampler/greedy
            rand_max: 0
        pub_transition_type: experiment/environment/sub_transition_type
      sub_ic_signal: experiment/environment/pub_ic_signal
    trigger: experiment/agent/trigger
    pub_ic_signal: experiment/environment/pub_ic_signal
  load_file: leo_leosim_sarsa_walk_egreedy_20-mp0-run0
  save_every: never
